name: 'Process Notebooks'
description: 'Run QA tools on Jupyter notebooks cross-platform'
inputs:
  command:
    description: 'Command to run (linter, formatter, pynblint, link_checker, doi_checker, execute)'
    required: true
  notebooks:
    description: 'JSON array of notebook paths'
    required: true
  pynblint_include_violations:
    description: 'List of violations to include when running pynblint (comma-separated)'
    required: false
    default: ''
runs:
  using: 'composite'
  steps:
    - name: Process notebooks
      shell: bash -l {0}
      run: |
        python3 - << 'EOF'
        import json
        import os
        import re
        import subprocess
        import sys

        from pathlib import Path

        command = "${{ inputs.command }}"
        notebooks_json = """${{ inputs.notebooks }}""".strip()

        valid_commands = ['linter', 'formatter', 'pynblint', 'link_checker', 'doi_checker', 'execute']
        if command not in valid_commands:
            print(f"Error: Invalid command '{command}'")
            print(f"Valid commands: {', '.join(valid_commands)}")
            sys.exit(1)

        if not notebooks_json:
            notebooks = []
        else:
            try:
                notebooks = json.loads(notebooks_json)
            except json.JSONDecodeError:
                print(f"Error: Invalid JSON format")
                sys.exit(1)

        result = 0

        for notebook in notebooks:
            if not notebook:
                continue

            print(f"Processing {notebook} with {command}")

            if command == "linter":
                cmd = ["nbqa", "ruff", "check", notebook]
            elif command == "formatter":
                cmd = ["nbqa", "ruff", "format", "--diff", notebook]
            elif command == "pynblint":
                notebook_name = Path(notebook).name
                lint_file = f"lint.{notebook_name}.json"
                cmd = ["pynblint", "--output", lint_file, notebook]
                include_violations_str = "${{ inputs.pynblint_include_violations }}".strip()
                if include_violations_str:
                    include_violations = [v.strip() for v in include_violations_str.split(',') if v.strip()]
                    if include_violations:
                        violations_json = '[' + ','.join(f'"{v}"' for v in include_violations) + ']'
                        cmd.extend(["--include", violations_json])
            elif command == "link_checker":
                cmd = ["pytest-check-links", notebook]
            elif command == "doi_checker":
                # Check for DOI in notebook
                # DOI regex patterns
                doi_patterns = [
                    r'10\.\d{4,9}/[-._;()/:A-Z0-9]+',  # Standard DOI format
                    r'doi\.org/(10\.\d{4,9}/[-._;()/:A-Z0-9]+)',  # doi.org URLs
                    r'https?://(?:dx\.)?doi\.org/(10\.\d{4,9}/[-._;()/:A-Z0-9]+)'  # Full DOI URLs
                ]

                # Metadata fields that might contain DOI references
                metadata_fields = ['references', 'citation', 'doi', 'reference', 'Attributes']

                # Read and parse notebook
                try:
                    with open(notebook, 'r', encoding='utf-8') as f:
                        nb_data = json.load(f)
                except Exception as e:
                    print(f"Error reading notebook {notebook}: {e}")
                    result = 1
                    continue

                # First, check if dataset metadata contains DOI references
                has_dataset_doi_metadata = False

                for cell in nb_data.get('cells', []):
                    if cell.get('cell_type') == 'code':
                        for output in cell.get('outputs', []):
                            # Check text outputs for dataset metadata with DOIs
                            if 'text' in output:
                                text = output['text']
                                if isinstance(text, list):
                                    text = ''.join(text)
                                # Check if this looks like xarray/dataset output with metadata
                                if any(field in text for field in metadata_fields):
                                    # Check if metadata contains DOI patterns
                                    for pattern in doi_patterns:
                                        if re.search(pattern, text, re.IGNORECASE):
                                            has_dataset_doi_metadata = True
                                            break

                            # Check data outputs for metadata
                            data = output.get('data', {})
                            for key, value in data.items():
                                if isinstance(value, (str, list)):
                                    if isinstance(value, list):
                                        value = ''.join(value)
                                    if any(field in value for field in metadata_fields):
                                        for pattern in doi_patterns:
                                            if re.search(pattern, value, re.IGNORECASE):
                                                has_dataset_doi_metadata = True
                                                break

                            if has_dataset_doi_metadata:
                                break

                    if has_dataset_doi_metadata:
                        break

                # If no dataset metadata with DOIs found, skip the check
                if not has_dataset_doi_metadata:
                    print(f"INFO: No dataset DOI metadata found in {notebook}, skipping DOI check")
                    continue

                # Dataset has DOI metadata, so we require DOI citations
                found_dois = set()

                # Search in all cells for DOI citations
                for cell in nb_data.get('cells', []):
                    # Check markdown cells
                    if cell.get('cell_type') == 'markdown':
                        source = cell.get('source', [])
                        if isinstance(source, list):
                            source = ''.join(source)
                        for pattern in doi_patterns:
                            matches = re.findall(pattern, source, re.IGNORECASE)
                            found_dois.update(matches)

                    # Check code cell outputs
                    if cell.get('cell_type') == 'code':
                        for output in cell.get('outputs', []):
                            # Check text outputs
                            if 'text' in output:
                                text = output['text']
                                if isinstance(text, list):
                                    text = ''.join(text)
                                for pattern in doi_patterns:
                                    matches = re.findall(pattern, text, re.IGNORECASE)
                                    found_dois.update(matches)

                            # Check data outputs (HTML, plain text, etc.)
                            data = output.get('data', {})
                            for key, value in data.items():
                                if isinstance(value, (str, list)):
                                    if isinstance(value, list):
                                        value = ''.join(value)
                                    for pattern in doi_patterns:
                                        matches = re.findall(pattern, value, re.IGNORECASE)
                                        found_dois.update(matches)

                # Validate DOI format
                valid_doi_pattern = re.compile(r'^10\.\d{4,9}/[-._;()/:A-Z0-9]+$', re.IGNORECASE)
                valid_dois = [doi for doi in found_dois if valid_doi_pattern.match(doi)]

                if not valid_dois:
                    print(f"ERROR: No valid DOI found in {notebook}")
                    print(f"  Notebook uses dataset with DOI metadata but doesn't cite the DOI")
                    print(f"  Please add DOI citation in markdown or ensure dataset metadata is visible")
                    print(f"  Expected format: 10.xxxx/xxxxx")
                    result = 1
                else:
                    print(f"Found {len(valid_dois)} valid DOI(s) in {notebook}:")
                    for doi in sorted(valid_dois):
                        print(f"  - {doi}")

                # Skip subprocess call for doi_checker
                continue
            elif command == "execute":
                # Create cdsapi config file if needed
                cdsapi_key = os.getenv("CDSAPI_KEY")
                if cdsapi_key:
                    print("Creating .cdsapirc file")
                    cdsapi_rc = Path.home() / ".cdsapirc"
                    if not cdsapi_rc.exists():
                        with open(cdsapi_rc, 'w') as f:
                            f.write("url: https://cds.climate.copernicus.eu/api\n")
                            f.write(f"key: {cdsapi_key}")

                # Setup output directory and path
                output_dir = os.getenv("QA_OUTPUT_DIR", "qa_outputs")
                Path(output_dir).mkdir(parents=True, exist_ok=True)

                # Create output path with .output suffix
                notebook_path = Path(notebook)
                output_name = notebook_path.stem + ".output" + notebook_path.suffix
                output_path = Path(output_dir) / output_name

                cmd = ["ploomber-engine", notebook, str(output_path), "--profile-memory"]

            try:
                subprocess.run(cmd, check=True)

                # Special handling for pynblint
                if command == "pynblint" and Path(lint_file).exists():
                    with open(lint_file, 'r') as f:
                        lint_data = json.load(f)
                    if any('recommendation' in lint for lint in lint_data.get('lints', [])):
                        print(f"Pynblint failed for {notebook}")
                        result = 1

            except subprocess.CalledProcessError:
                print(f"{command} failed for {notebook}")
                result = 1
            except Exception as e:
                print(f"Error processing {notebook}: {e}")
                result = 1

        sys.exit(result)
        EOF
